{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import reduce\n",
    "import pickle\n",
    "import compress_pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The given result is produced by an AWS EC2 `r5.4xlarge` machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Configurable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation task in a case\n",
    "num_clients = 10  # how many clients' data to aggregate\n",
    "element_bits = 16  # number of bits per element in a client's data\n",
    "\n",
    "# Test cases\n",
    "plaintext_lengths = [16384, 65536, 262144]\n",
    "algorithms = [\"Paillier\", \"Paillier+batch\", \"BFV\", \"BFV+batch\", \"CKKS\", \"CKKS+batch\", \"FLASHE\"]\n",
    "\n",
    "# Format of the results\n",
    "cols = ['Plaintext', 'Ciphertext', 'Encryption', 'Decryption', 'Addition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables that one should not change its definition\n",
    "# Affecting the efficiency\n",
    "MAGIC_N_JOBS = 50\n",
    "\n",
    "# To account for the worst-case overflow encountered during aggregation\n",
    "additional_bits = int(np.ceil(np.log2(num_clients + 1)))\n",
    "# After aggregation, number of bits per element in the server's sum\n",
    "actual_element_bits = element_bits + additional_bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Quantization Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.secureprotol.jzf_aciq import ACIQ\n",
    "from federatedml.secureprotol.jzf_quantize import \\\n",
    "    _static_quantize_padding, _static_unquantize_padding\n",
    "\n",
    "def get_alpha_r_max(trainable_list, element_bits):\n",
    "    local_min_list = []\n",
    "    local_max_list = []\n",
    "    size_list = []\n",
    "    for idx, trainable in enumerate(trainable_list):\n",
    "        local_min = []\n",
    "        local_max = []\n",
    "        for layer in trainable:\n",
    "            local_min.append(np.amin(layer))\n",
    "            local_max.append(np.amax(layer))\n",
    "\n",
    "            if idx == 0:\n",
    "                size_list.append(layer.size)\n",
    "\n",
    "        local_min_list.append(np.array(local_min))\n",
    "        local_max_list.append(np.array(local_max))\n",
    "\n",
    "    local_min_list = np.array(local_min_list)\n",
    "    local_max_list = np.array(local_max_list)\n",
    "\n",
    "    min_list = np.amin(local_min_list, 0)\n",
    "    max_list = np.amax(local_max_list, 0)\n",
    "\n",
    "    n = len(trainable_list)\n",
    "    aciq = ACIQ(element_bits)\n",
    "\n",
    "    alpha_list = []\n",
    "    r_max_list = []\n",
    "    layer_cnt = 0\n",
    "    for min, max in zip(min_list, max_list):\n",
    "        alpha = aciq.get_alpha_gaus(min, max, size_list[layer_cnt])\n",
    "\n",
    "        r_max = alpha * num_clients\n",
    "\n",
    "        alpha_list.append(alpha)\n",
    "        r_max_list.append(r_max)\n",
    "        layer_cnt += 1\n",
    "\n",
    "    return alpha_list, r_max_list\n",
    "\n",
    "def quantize(trainable_list, element_bits):\n",
    "    n = len(trainable_list)\n",
    "    alpha_list, r_max_list = get_alpha_r_max(trainable_list,\n",
    "                                            element_bits)\n",
    "    quantized = []\n",
    "    for _, trainable in enumerate(trainable_list):\n",
    "        quantized_layers = []\n",
    "        for idx, layer in enumerate(trainable):\n",
    "            shape = layer.shape\n",
    "            layer_flatten = layer.flatten()\n",
    "            ret = _static_quantize_padding(layer_flatten,\n",
    "                                           alpha_list[idx],\n",
    "                                           element_bits,\n",
    "                                           n)\n",
    "            ret = np.array(ret).reshape(shape)\n",
    "            quantized_layers.append(ret)\n",
    "        quantized.append(np.array(quantized_layers))\n",
    "    return np.array(quantized), np.array(alpha_list)\n",
    "\n",
    "def unquantize(trainable, alpha_list, element_bits, num_clients):\n",
    "    layers = []\n",
    "    for idx, layer in enumerate(trainable):\n",
    "        shape = layer.shape\n",
    "        layer_flatten = layer.flatten()\n",
    "        ret = _static_unquantize_padding(layer_flatten,\n",
    "                                         alpha_list[idx],\n",
    "                                         element_bits,\n",
    "                                         num_clients)\n",
    "        ret = np.array(ret).reshape(shape)\n",
    "        layers.append(ret)\n",
    "\n",
    "    layers = np.array(layers)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Batching Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.secureprotol.jzf_quantize import \\\n",
    "    _static_batching_padding, _static_unbatching_padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Encryption Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 FLASHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.secureprotol.jzf_flashe import FlasheCipher\n",
    "flashe = FlasheCipher(actual_element_bits)\n",
    "flashe.set_num_clients(num_clients)\n",
    "flashe.generate_prp_seed()\n",
    "flashe.set_iter_index(0)\n",
    "flashe.idx = 0\n",
    "\n",
    "def flashe_encrypt(value):\n",
    "    return flashe.encrypt(value)\n",
    "\n",
    "def flashe_decrypt(value):\n",
    "    flashe.set_idx_list(raw_idx_list=[0] * num_clients, mode=\"decrypt\")\n",
    "    return flashe.decrypt(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.secureprotol.jzf_paillier import PaillierCipher\n",
    "paillier = PaillierCipher()\n",
    "paillier.generate_key(n_length=2048)\n",
    "\n",
    "def paillier_encrypt(value):\n",
    "    return paillier.encrypt(value)\n",
    "\n",
    "def paillier_decrypt(value):\n",
    "    return paillier.decrypt(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 BFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.secureprotol.jzf_bfv import BFVCipher\n",
    "bfv = BFVCipher(p=128, m=2048)\n",
    "# # bfv = BFVCipher(p=1964769281, m=8192, flagBatching=True)\n",
    "bfv.generate_key()\n",
    "\n",
    "def bfv_encrypt(value):\n",
    "    return bfv.encrypt(value)\n",
    "\n",
    "def bfv_decrypt(value):\n",
    "    return bfv.decrypt(value)\n",
    "\n",
    "from federatedml.secureprotol.jzf_bfv import BFVCipher\n",
    "# p needs to be prime and p-1 must be multiple of 2*m\n",
    "# bfv_2 = BFVCipher(p=65537, m=2048, flagBatching=True)\n",
    "bfv_2 = BFVCipher(p=1964769281, m=8192, flagBatching=True)\n",
    "bfv_2.generate_key()\n",
    "\n",
    "def bfv_batch_encrypt(value):\n",
    "    return bfv_2.encrypt(value)\n",
    "\n",
    "def bfv_batch_decrypt(value):\n",
    "    return bfv_2.decrypt(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 CKKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.secureprotol.jzf_ckks import CKKSCipher\n",
    "ckks = CKKSCipher(8192, None, 2 ** 40)\n",
    "\n",
    "def ckks_batch_encrypt(value):\n",
    "    return ckks.encrypt(value)\n",
    "\n",
    "def ckks_batch_decrypt(value):\n",
    "    return ckks.decrypt(value)\n",
    "\n",
    "def ckks_encrypt(value):\n",
    "    return ckks.encrypt_no_batch(value)\n",
    "\n",
    "def ckks_decrypt(value):\n",
    "    return ckks.decrypt_no_batch(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_an_algorithm(plaintext, quantized_plaintext, alphas, algorithm, plaintext_size, no_add=False):\n",
    "    print(f'\\tStart testing {algorithm}')\n",
    "    \n",
    "    ### Step 0/5: Configuration\n",
    "    if algorithm == \"FLASHE\" or algorithm == \"FLASHE+batch\":\n",
    "        num_bits_per_batch = flashe.int_bits\n",
    "    elif algorithm == \"Paillier\" or algorithm == \"Paillier+batch\":\n",
    "        num_bits_per_batch = (paillier.get_n() ** 2).bit_length()\n",
    "    else:\n",
    "        num_bits_per_batch = None\n",
    "    \n",
    "    begin_time = time.time()\n",
    "\n",
    "    ### Step 1/5: Encryption\n",
    "    if algorithm == \"FLASHE\":\n",
    "        ciphertext = flashe_encrypt(quantized_plaintext)\n",
    "    elif algorithm == \"FLASHE+batch\":\n",
    "        shape = quantized_plaintext.shape\n",
    "        ciphertext = _static_batching_padding(\n",
    "            quantized_plaintext,\n",
    "            num_bits_per_batch,\n",
    "            element_bits,\n",
    "            additional_bits\n",
    "        )\n",
    "        ciphertext = flashe_encrypt(quantized_plaintext)\n",
    "    elif algorithm == \"Paillier\":\n",
    "        ciphertext = paillier_encrypt(quantized_plaintext)\n",
    "    elif algorithm == \"Paillier+batch\":\n",
    "        shape = quantized_plaintext.shape\n",
    "        plaintext = _static_batching_padding(\n",
    "            quantized_plaintext,\n",
    "            paillier.key_length,\n",
    "            element_bits,\n",
    "            additional_bits\n",
    "        )\n",
    "        ciphertext = paillier_encrypt(quantized_plaintext)\n",
    "    elif algorithm == \"BFV\":\n",
    "        shape = quantized_plaintext.shape\n",
    "        ciphertext = bfv_encrypt(quantized_plaintext)\n",
    "    elif algorithm == \"BFV+batch\":\n",
    "        quantized_plaintext = quantized_plaintext.astype(np.int64)\n",
    "        shape = quantized_plaintext.shape\n",
    "        quantized_plaintext = quantized_plaintext.flatten()\n",
    "        ciphertext = bfv_batch_encrypt(quantized_plaintext)\n",
    "    elif algorithm == \"CKKS\":\n",
    "        ciphertext = ckks_encrypt(plaintext)\n",
    "    elif algorithm == \"CKKS+batch\":\n",
    "        ciphertext = ckks_batch_encrypt(plaintext)\n",
    "        \n",
    "    encryption_time = time.time()\n",
    "    encryption_duration = round(encryption_time - begin_time, 4)\n",
    "    print(f'\\t\\tEncryption: {encryption_duration} sec')\n",
    "    \n",
    "    ### Step 2/5: Measure ciphertext size\n",
    "    if algorithm == \"FLASHE\" or algorithm == \"FLASHE+batch\":\n",
    "        compressed_ciphertext = compress_multi(ciphertext.flatten().astype(object), num_bits_per_batch)\n",
    "    elif algorithm == \"Paillier\" or algorithm == \"Paillier+batch\":\n",
    "        compressed_ciphertext = compress_multi(ciphertext.flatten().astype(object), num_bits_per_batch)\n",
    "    elif algorithm == \"BFV\" or algorithm == \"BFV+batch\" or algorithm == \"CKKS\" or algorithm == \"CKKS+batch\":\n",
    "        compressed_ciphertext = ciphertext\n",
    "#     a_e_b = compress_pickle.dumps(a_e_c, 'bz2')\n",
    "    compressed_ciphertext_bytes = pickle.dumps(compressed_ciphertext)\n",
    "    ciphertext_size = len(compressed_ciphertext_bytes)\n",
    "    \n",
    "    print(f'\\t\\tPlaintext {plaintext_size} bytes')\n",
    "    print(f'\\t\\tCiphertext {ciphertext_size} bytes')\n",
    "    t_c = time.time()\n",
    "    \n",
    "    ### Step 3/5: Addition\n",
    "    ciphertext_list = [ciphertext] * num_clients\n",
    "    if algorithm == \"FLASHE\" or algorithm == \"FLASHE+batch\":\n",
    "        mod = 1 << 128\n",
    "        aggregated_ciphertext = reduce(lambda x, y: (x + y) % mod, ciphertext_list)\n",
    "    elif algorithm == \"Paillier\" or algorithm == \"Paillier+batch\":\n",
    "        mod = paillier.get_n() ** 2\n",
    "        aggregated_ciphertext = reduce(lambda x, y: (x * y) % mod, ciphertext_list)  # * instead of + !\n",
    "    elif algorithm == \"BFV\":\n",
    "        if no_add:\n",
    "            aggregated_ciphertext = ciphertext  # skip aggregation as indicated by no_add\n",
    "        else:\n",
    "            aggregated_ciphertext = bfv.sum(ciphertext_list)\n",
    "    elif algorithm == \"BFV+batch\":\n",
    "        aggregated_ciphertext = bfv_2.sum(ciphertext_list)\n",
    "    elif algorithm == \"CKKS\":\n",
    "        aggregated_ciphertext = ckks.sum_no_batch(ciphertext_list)\n",
    "    elif algorithm == \"CKKS+batch\":\n",
    "        aggregated_ciphertext = ckks.sum(ciphertext_list)\n",
    "    \n",
    "    addition_time = time.time()\n",
    "    addition_duration = round(addition_time - encryption_time, 4)\n",
    "    print(f'\\t\\tAddition: {addition_duration} sec')\n",
    "    \n",
    "    ### Step 4/5: Decryption\n",
    "    if algorithm == \"FLASHE\":\n",
    "        quantized_sum = flashe_decrypt(aggregated_ciphertext)\n",
    "    elif algorithm == \"FLASHE+batch\":\n",
    "        quantized_sum = flashe_decrypt(aggregated_ciphertext)\n",
    "        quantized_sum = _static_unbatching_padding(\n",
    "            quantized_sum, num_bits_per_batch, element_bits, additional_bits\n",
    "        )\n",
    "        quantized_sum = quantized_sum[:(int(np.prod(shape)))]\n",
    "        quantized_sum = quantized_sum.reshape(shape)\n",
    "    elif algorithm == \"Paillier\":\n",
    "        quantized_sum = paillier_decrypt(aggregated_ciphertext)\n",
    "    elif algorithm == \"Paillier+batch\":\n",
    "        quantized_sum = paillier_decrypt(aggregated_ciphertext)\n",
    "        quantized_sum = _static_unbatching_padding(\n",
    "            quantized_sum, paillier.key_length, element_bits, additional_bits\n",
    "        )\n",
    "        quantized_sum = quantized_sum[:(int(np.prod(shape)))]\n",
    "        quantized_sum = quantized_sum.reshape(shape)\n",
    "    elif algorithm == \"BFV\":\n",
    "        quantized_sum = bfv_decrypt(aggregated_ciphertext)\n",
    "    elif algorithm == \"BFV+batch\":\n",
    "        quantized_sum = bfv_batch_decrypt(aggregated_ciphertext)\n",
    "        quantized_sum = np.array(quantized_sum, dtype=np.int64)\n",
    "        quantized_sum = quantized_sum[:(int(np.prod(shape)))]\n",
    "        quantized_sum = quantized_sum.reshape(shape)\n",
    "    elif algorithm == \"CKKS\":\n",
    "        quantized_sum = ckks_decrypt(aggregated_ciphertext)\n",
    "    elif algorithm == \"CKKS+batch\":\n",
    "        quantized_sum = ckks_batch_decrypt(aggregated_ciphertext)\n",
    "    \n",
    "    decryption_time = time.time()\n",
    "    decryption_duration = round(decryption_time - addition_time, 4)\n",
    "    print(f'\\t\\tDecryption: {decryption_duration} sec')\n",
    "    \n",
    "    ### Step 5/5: Dequantization\n",
    "    if algorithm == \"CKKS\" or algorithm == \"CKKS+batch\":\n",
    "        final_sum = [quantized_sum]\n",
    "    else:\n",
    "        if algorithm == \"BFV\" or algorithm == \"BFV+batch\":\n",
    "            quantized_sum = np.array(quantized_sum).reshape(shape)\n",
    "        print(f'\\t\\tQuantized sum (first 5): {quantized_sum[0][:5]}')\n",
    "        print(f'\\t\\tQuantized sum (last 5): = {quantized_sum[0][-5:]}')\n",
    "        final_sum = unquantize(quantized_sum, alphas, element_bits, num_clients)\n",
    "    \n",
    "    print(f'\\t\\tFinal sum (first 5): {[round(e, 4) for e in final_sum[0][:5]]}')\n",
    "    print(f'\\t\\tFinal sum (last 5): = {[round(e, 4) for e in final_sum[0][-5:]]}')\n",
    "    return encryption_duration, addition_duration, decryption_duration, ciphertext_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_d():\n",
    "    return defaultdict(rec_d)\n",
    "\n",
    "def chunks_idx(l, n):\n",
    "    d, r = divmod(len(l), n)\n",
    "    for i in range(n):\n",
    "        si = (d+1)*(i if i < r else r) + d*(0 if i < r else i - r)\n",
    "        yield si, si+(d+1 if i < r else d)\n",
    "\n",
    "def _compress(flatten_array, num_bits):\n",
    "    res = 0\n",
    "    l = len(flatten_array)\n",
    "    for element in flatten_array:\n",
    "        res <<= num_bits\n",
    "        res += element\n",
    "\n",
    "    return res, l\n",
    "\n",
    "def compress_multi(flatten_array, num_bits):\n",
    "    l = len(flatten_array)\n",
    "    \n",
    "    pool_inputs = []\n",
    "    sizes = []\n",
    "    pool = Pool(MAGIC_N_JOBS)\n",
    "    \n",
    "    for begin, end in chunks_idx(range(l), MAGIC_N_JOBS):\n",
    "        sizes.append(end - begin)\n",
    "        \n",
    "        pool_inputs.append([flatten_array[begin:end], num_bits])\n",
    "\n",
    "    pool_outputs = pool.starmap(_compress, pool_inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    res = 0\n",
    "\n",
    "    for idx, output in enumerate(pool_outputs):\n",
    "        res +=  output[0] << (int(np.sum(sizes[idx + 1:])) * num_bits)\n",
    "    \n",
    "    num_bytes = (num_bits * l - 1) // 8 + 1\n",
    "    res = res.to_bytes(num_bytes, 'big')\n",
    "    return res, l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Data Generation and Quantization\n",
    "\n",
    "plaintext_dict = {}\n",
    "plaintext_size_dict = {}\n",
    "quantized_plaintext_dict = {}\n",
    "baseline_sum_dict = {}\n",
    "for plaintext_length in plaintext_lengths:\n",
    "    print(f'[CASE] {plaintext_length}')\n",
    "\n",
    "    ### Generate a random array as plaintext\n",
    "    begin_time = time.time()\n",
    "    plaintext = np.random.random(plaintext_length)\n",
    "    print(f'\\tPlaintext (first 5): {[round(e, 4) for e in plaintext[:5]]}')  # for preview\n",
    "    print(f'\\tPlaintext (last 5): {[round(e, 4) for e in plaintext[-5:]]}')\n",
    "    generate_time = time.time()\n",
    "    print(f'\\tGenerate data: {round(generate_time - begin_time, 4)} sec')\n",
    "\n",
    "    ### Quantize the array\n",
    "    ### (Need to reshape the data to fit the interface of `quantize`)\n",
    "    quantized_plaintext, alphas = quantize([[plaintext]], element_bits)\n",
    "    quantized_plaintext = quantized_plaintext[0]\n",
    "\n",
    "    ### Measure the size of **the sum of** such quantized arrays as the plaintext size\n",
    "    ### a) We do padding (using actual_elements_bits instead of elements_bits) \n",
    "    ### to be consistent with the ciphertext which can be the sum and overflow\n",
    "    ### b) We do compression to measure the precise size\n",
    "    big_number = compress_multi(quantized_plaintext[0], actual_element_bits) \n",
    "    #     a_b = compress_pickle.dumps(big_number, 'bz2')\n",
    "    bytes_representation = pickle.dumps(big_number)\n",
    "    plaintext_size = len(bytes_representation)\n",
    "\n",
    "    ### Then calculate the baseline sum, using plaintext addition\n",
    "    baseline_sum = (np.array(plaintext) * num_clients).tolist()\n",
    "\n",
    "    ### Bookkeep what we have computed so far\n",
    "    plaintext_dict[plaintext_length] = plaintext\n",
    "    quantized_plaintext_dict[plaintext_length] = quantized_plaintext\n",
    "    plaintext_size_dict[plaintext_length] = plaintext_size\n",
    "    baseline_sum_dict[plaintext_length] = baseline_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual experiments: Encryption, Aggregation, Decryption\n",
    "result_dict = rec_d()\n",
    "for algorithm in algorithms:\n",
    "    for plaintext_length in plaintext_lengths:\n",
    "        print(algorithm, plaintext_length)\n",
    "        \n",
    "        # Show the baseline results\n",
    "        # and the actual results should be close to them\n",
    "        baseline_sum = baseline_sum_dict[plaintext_length]\n",
    "        print(f'\\tBaseline sum (first 5): {[round(e, 2) for e in baseline_sum[:5]]}')\n",
    "        print(f'\\tBaseline sum (last 5): {[round(e, 2) for e in baseline_sum[-5:]]}')\n",
    "        \n",
    "        # Skip those experiments that are observed to render OOM errors\n",
    "        no_add = False\n",
    "        if plaintext_length > 65536:\n",
    "            if algorithm == \"BFV\":\n",
    "                continue\n",
    "        if plaintext_length > 16384:\n",
    "            if algorithm == \"CKKS\":\n",
    "                continue\n",
    "            if algorithm == \"BFV\":\n",
    "                no_add = True\n",
    "\n",
    "        # Unit test: Encryption -> Aggregation -> Decryption\n",
    "        plaintext_size = plaintext_size_dict[plaintext_length]\n",
    "        encrypt_time, aggregate_time, decrypt_time, ciphertext_size \\\n",
    "            = test_an_algorithm(\n",
    "                plaintext=plaintext_dict[plaintext_length],\n",
    "                quantized_plaintext=quantized_plaintext_dict[plaintext_length],\n",
    "                alphas=alphas,\n",
    "                algorithm=algorithm,\n",
    "                plaintext_size=plaintext_size,\n",
    "                no_add=no_add\n",
    "            )\n",
    "\n",
    "        # Bookkeeping the results\n",
    "        result_dict[plaintext_length][algorithm]['Encryption'] = encrypt_time\n",
    "        result_dict[plaintext_length][algorithm]['Addition'] = aggregate_time\n",
    "        result_dict[plaintext_length][algorithm]['Decryption'] = decrypt_time\n",
    "        result_dict[plaintext_length][algorithm]['Plaintext'] = plaintext_size\n",
    "        result_dict[plaintext_length][algorithm]['Ciphertext'] = ciphertext_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(os.getcwd(), 'big-table.bin')\n",
    "pickle.dump(result_dict, open(save_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plaintext_length in plaintext_lengths:\n",
    "    print(f'[CASE] {plaintext_length}')\n",
    "    \n",
    "    table = {}\n",
    "    for col in cols:\n",
    "        l = []\n",
    "        for algorithm in algorithms:\n",
    "            # Skip those experiments that are observed to render OOM errors\n",
    "            if plaintext_length > 16384:\n",
    "                if algorithm == \"CKKS\":\n",
    "                    continue\n",
    "            if plaintext_length > 65536:\n",
    "                if algorithm == \"BFV\":\n",
    "                    continue\n",
    "                    \n",
    "            # Formatting the results\n",
    "            if col in ['Plaintext', 'Ciphertext']:  # Size of objects\n",
    "                kb = result_dict[plaintext_length][algorithm][col] / 1024\n",
    "                if kb >= 1024:\n",
    "                    mb = kb / 1024\n",
    "                    if mb > 1024:\n",
    "                        gb = mb / 1024\n",
    "                        l.append('{:.2f} GB'.format(gb))\n",
    "                    else:\n",
    "                        l.append('{:.2f} MB'.format(mb))\n",
    "                else:\n",
    "                    l.append('{:.2f} KB'.format(kb))\n",
    "            else:  # Time in seconds\n",
    "                l.append('{:.2f} s'.format(result_dict[plaintext_length][algorithm][col]))\n",
    "        table[col] = l\n",
    "\n",
    "    if plaintext_length > 65536:\n",
    "        data_frame = pd.DataFrame(data=table, index=algorithms[:2] + algorithms[3:4] + algorithms[5:])\n",
    "    elif plaintext_length > 16384:\n",
    "        data_frame = pd.DataFrame(data=table, index=algorithms[:4] + algorithms[5:])\n",
    "    else:\n",
    "        data_frame = pd.DataFrame(data=table, index=algorithms)\n",
    "    print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
