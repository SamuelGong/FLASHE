{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import reduce\n",
    "import compress_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration\n",
    "test_cases = [16384, 65536, 262144]\n",
    "# test_cases = [4096, 16384, 65536, 262144, 1048576]\n",
    "# test_cases = [10000, 100000, 1000000]\n",
    "# test_cases = [1024, 2048, 4096, 8192]\n",
    "# test_cases = [100000]\n",
    "# there is a limit regarding BFV+batch\n",
    "# ref: https://github.com/OpenMined/TenSEAL/issues/19#issuecomment-617067414\n",
    "# algos = [\"FLASHE+batch\"]\n",
    "algos = [\"FLASHE\", \"Paillier\", \"Paillier+batch\", \"BFV\", \"BFV+batch\", \"CKKS\", \"CKKS+batch\"]\n",
    "# algos = [\"BFV+batch\"]\n",
    "# algos = [\"BFV\", \"BFV+batch\"]\n",
    "# algos = [\"FLASHE\", \"FLASHE+batch\"]\n",
    "\n",
    "# when we have 10 operands for aggregation\n",
    "# for BFV without bathcing, the upper bound of element_bits is 61 -- determined by the length of C long\n",
    "# for BFV with batching, the upperbound of element_bits is 27 -- may be determined by the plaintext modulus 1964769281 \n",
    "element_bits = 16\n",
    "num_clients = 10\n",
    "MAGIC_N_JOBS = 50\n",
    "additional_bits = int(np.ceil(np.log2(num_clients + 1)))\n",
    "int_bits = element_bits + additional_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quantization\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from federatedml.secureprotol.jzf_aciq import ACIQ\n",
    "from federatedml.secureprotol.jzf_quantize import \\\n",
    "    _static_quantize_padding, _static_unquantize_padding\n",
    "\n",
    "def get_alpha_r_max(trainable_list, element_bits):\n",
    "    local_min_list = []\n",
    "    local_max_list = []\n",
    "    size_list = []\n",
    "    for idx, trainable in enumerate(trainable_list):\n",
    "        local_min = []\n",
    "        local_max = []\n",
    "        for layer in trainable:\n",
    "            local_min.append(np.amin(layer))\n",
    "            local_max.append(np.amax(layer))\n",
    "\n",
    "            if idx == 0:\n",
    "                size_list.append(layer.size)\n",
    "\n",
    "        local_min_list.append(np.array(local_min))\n",
    "        local_max_list.append(np.array(local_max))\n",
    "\n",
    "    local_min_list = np.array(local_min_list)\n",
    "    local_max_list = np.array(local_max_list)\n",
    "\n",
    "    min_list = np.amin(local_min_list, 0)\n",
    "    max_list = np.amax(local_max_list, 0)\n",
    "\n",
    "    n = len(trainable_list)\n",
    "    aciq = ACIQ(element_bits)\n",
    "\n",
    "    alpha_list = []\n",
    "    r_max_list = []\n",
    "    layer_cnt = 0\n",
    "    for min, max in zip(min_list, max_list):\n",
    "        alpha = aciq.get_alpha_gaus(min, max, size_list[layer_cnt])\n",
    "\n",
    "        r_max = alpha * num_clients\n",
    "\n",
    "        alpha_list.append(alpha)\n",
    "        r_max_list.append(r_max)\n",
    "        layer_cnt += 1\n",
    "\n",
    "    return alpha_list, r_max_list\n",
    "\n",
    "def quantize(trainable_list, element_bits):\n",
    "    n = len(trainable_list)\n",
    "    alpha_list, r_max_list = get_alpha_r_max(trainable_list,\n",
    "                                            element_bits)\n",
    "    quantized = []\n",
    "    for _, trainable in enumerate(trainable_list):\n",
    "        quantized_layers = []\n",
    "        for idx, layer in enumerate(trainable):\n",
    "            shape = layer.shape\n",
    "            layer_flatten = layer.flatten()\n",
    "            ret = _static_quantize_padding(layer_flatten,\n",
    "                                           alpha_list[idx],\n",
    "                                           element_bits,\n",
    "                                           n)\n",
    "            ret = np.array(ret).reshape(shape)\n",
    "            quantized_layers.append(ret)\n",
    "        quantized.append(np.array(quantized_layers))\n",
    "    return np.array(quantized), np.array(alpha_list)\n",
    "\n",
    "def unquantize(trainable, alpha_list, element_bits, num_clients):\n",
    "    layers = []\n",
    "    for idx, layer in enumerate(trainable):\n",
    "        shape = layer.shape\n",
    "        layer_flatten = layer.flatten()\n",
    "        ret = _static_unquantize_padding(layer_flatten,\n",
    "                                         alpha_list[idx],\n",
    "                                         element_bits,\n",
    "                                         num_clients)\n",
    "        ret = np.array(ret).reshape(shape)\n",
    "        layers.append(ret)\n",
    "\n",
    "    layers = np.array(layers)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.secureprotol.jzf_quantize import \\\n",
    "    _static_batching_padding, _static_unbatching_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks_idx(l, n):\n",
    "    d, r = divmod(len(l), n)\n",
    "    for i in range(n):\n",
    "        si = (d+1)*(i if i < r else r) + d*(0 if i < r else i - r)\n",
    "        yield si, si+(d+1 if i < r else d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compress(flatten_array, num_bits):\n",
    "    res = 0\n",
    "    l = len(flatten_array)\n",
    "    for element in flatten_array:\n",
    "        res <<= num_bits\n",
    "        res += element\n",
    "\n",
    "    return res, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_multi(flatten_array, num_bits):\n",
    "    l = len(flatten_array)\n",
    "    \n",
    "    pool_inputs = []\n",
    "    sizes = []\n",
    "    pool = Pool(MAGIC_N_JOBS)\n",
    "    \n",
    "    for begin, end in chunks_idx(range(l), MAGIC_N_JOBS):\n",
    "        sizes.append(end - begin)\n",
    "        \n",
    "        pool_inputs.append([flatten_array[begin:end], num_bits])\n",
    "\n",
    "    pool_outputs = pool.starmap(_compress, pool_inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    res = 0\n",
    "\n",
    "    for idx, output in enumerate(pool_outputs):\n",
    "        res +=  output[0] << (int(np.sum(sizes[idx + 1:])) * num_bits)\n",
    "    \n",
    "    num_bytes = (num_bits * l - 1) // 8 + 1\n",
    "    res = res.to_bytes(num_bytes, 'big')\n",
    "    return res, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'federatedml.secureprotol.affine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b253f9969f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mflashe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfederatedml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecureprotol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjzf_paillier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPaillierCipher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mpaillier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPaillierCipher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpaillier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repository/code/secure-aggregation/FLASHE/federatedml/secureprotol/jzf_paillier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfederatedml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecureprotol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencrypt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncrypt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfederatedml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecureprotol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgmpy_math\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repository/code/secure-aggregation/FLASHE/federatedml/secureprotol/encrypt.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# from arch.api.utils import log_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfederatedml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecureprotol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgmpy_math\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfederatedml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecureprotol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAffineCipher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfederatedml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecureprotol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfate_paillier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPaillierKeypair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfederatedml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecureprotol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomPads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'federatedml.secureprotol.affine'"
     ]
    }
   ],
   "source": [
    "### Encryption\n",
    "from federatedml.secureprotol.jzf_flashe import FlasheCipher\n",
    "flashe = FlasheCipher(20)\n",
    "flashe.set_num_clients(num_clients)\n",
    "flashe.generate_prp_seed()\n",
    "flashe.set_iter_index(0)\n",
    "flashe.idx = 0\n",
    "\n",
    "def flashe_encrypt(value):\n",
    "    return flashe.encrypt(value)\n",
    "\n",
    "def flashe_decrypt(value):\n",
    "    flashe.set_idx_list(raw_idx_list=[0] * num_clients, mode=\"decrypt\")\n",
    "    return flashe.decrypt(value)\n",
    "\n",
    "from federatedml.secureprotol.jzf_paillier import PaillierCipher\n",
    "paillier = PaillierCipher()\n",
    "paillier.generate_key(n_length=2048)\n",
    "\n",
    "def paillier_encrypt(value):\n",
    "    return paillier.encrypt(value)\n",
    "\n",
    "def paillier_decrypt(value):\n",
    "    return paillier.decrypt(value)\n",
    "\n",
    "from federatedml.secureprotol.jzf_bfv import BFVCipher\n",
    "bfv = BFVCipher(p=128, m=2048)\n",
    "# # bfv = BFVCipher(p=1964769281, m=8192, flagBatching=True)\n",
    "bfv.generate_key()\n",
    "\n",
    "def bfv_encrypt(value):\n",
    "    return bfv.encrypt(value)\n",
    "\n",
    "def bfv_decrypt(value):\n",
    "    return bfv.decrypt(value)\n",
    "\n",
    "from federatedml.secureprotol.jzf_bfv import BFVCipher\n",
    "# p needs to be prime and p-1 must be multiple of 2*m\n",
    "# bfv_2 = BFVCipher(p=65537, m=2048, flagBatching=True)\n",
    "bfv_2 = BFVCipher(p=1964769281, m=8192, flagBatching=True)\n",
    "bfv_2.generate_key()\n",
    "\n",
    "def bfv_batch_encrypt(value):\n",
    "    return bfv_2.encrypt(value)\n",
    "\n",
    "def bfv_batch_decrypt(value):\n",
    "    return bfv_2.decrypt(value)\n",
    "\n",
    "print(int(1964769281).bit_length())\n",
    "\n",
    "from federatedml.secureprotol.jzf_ckks import CKKSCipher\n",
    "ckks = CKKSCipher(8192, None, 2 ** 40)\n",
    "\n",
    "def ckks_batch_encrypt(value):\n",
    "    return ckks.encrypt(value)\n",
    "\n",
    "def ckks_batch_decrypt(value):\n",
    "    return ckks.decrypt(value)\n",
    "\n",
    "def ckks_encrypt(value):\n",
    "    return ckks.encrypt_no_batch(value)\n",
    "\n",
    "def ckks_decrypt(value):\n",
    "    return ckks.decrypt_no_batch(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((paillier.get_n() ** 2).bit_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_an_algo(a, a_q, alphas, algo, no_add=False):\n",
    "    print(f'\\t{algo}')\n",
    "    \n",
    "    if algo == \"FLASHE\" or algo == \"FLASHE+batch\":\n",
    "        int_bits = flashe.int_bits\n",
    "    elif algo == \"Paillier\" or algo == \"Paillier+batch\":\n",
    "        int_bits = (paillier.get_n() ** 2).bit_length()\n",
    "    else:\n",
    "        int_bits = None\n",
    "    \n",
    "    begin = time.time()\n",
    "    ### perform encryption\n",
    "    if algo == \"FLASHE\":\n",
    "        a_e = flashe_encrypt(a_q)\n",
    "    elif algo == \"FLASHE+batch\":\n",
    "        shape = a_q.shape\n",
    "        a_q = _static_batching_padding(a_q, int_bits, element_bits, additional_bits)\n",
    "        a_e = flashe_encrypt(a_q)\n",
    "    elif algo == \"Paillier\":\n",
    "        a_e = paillier_encrypt(a_q)\n",
    "    elif algo == \"Paillier+batch\":\n",
    "        shape = a_q.shape\n",
    "        a_q = _static_batching_padding(a_q, paillier.key_length, element_bits, additional_bits)\n",
    "        a_e = paillier_encrypt(a_q)\n",
    "    elif algo == \"BFV\":\n",
    "        shape = a_q.shape\n",
    "        a_e = bfv_encrypt(a_q)\n",
    "    elif algo == \"BFV+batch\":\n",
    "        a_q = a_q.astype(np.int64)\n",
    "        shape = a_q.shape\n",
    "        a_q = a_q.flatten()\n",
    "        a_e = bfv_batch_encrypt(a_q)\n",
    "    elif algo == \"CKKS\":\n",
    "        a_e = ckks_encrypt(a)\n",
    "    elif algo == \"CKKS+batch\":\n",
    "        a_e = ckks_batch_encrypt(a)\n",
    "        \n",
    "    t_e = time.time()\n",
    "    print(f'\\t\\tEncryption: {t_e - begin} sec')\n",
    "    \n",
    "    if algo == \"FLASHE\" or algo == \"FLASHE+batch\":\n",
    "        a_e_c = compress_multi(a_e.flatten().astype(object), int_bits)\n",
    "    elif algo == \"Paillier\" or algo == \"Paillier+batch\":\n",
    "        a_e_c = compress_multi(a_e.flatten().astype(object), int_bits)\n",
    "    elif algo == \"BFV\" or algo == \"BFV+batch\" or algo == \"CKKS\" or algo == \"CKKS+batch\":\n",
    "        a_e_c = a_e\n",
    "\n",
    "#     a_e_b = compress_pickle.dumps(a_e_c, 'bz2')\n",
    "    a_e_b = pickle.dumps(a_e_c)\n",
    "    l_e_c = len(a_e_b)\n",
    "    \n",
    "    print(f'\\t\\tPlaintext {l_c} bytes')\n",
    "    print(f'\\t\\tCiphertext {l_e_c} bytes')\n",
    "    t_c = time.time()\n",
    "    \n",
    "    ### perform addition\n",
    "    operands = [a_e] * num_clients\n",
    "    if algo == \"FLASHE\" or algo == \"FLASHE+batch\":\n",
    "        mod = 1 << 128\n",
    "        a_a = reduce(lambda x, y: (x + y) % mod, operands)\n",
    "    elif algo == \"Paillier\" or algo == \"Paillier+batch\":\n",
    "        mod = paillier.get_n() ** 2\n",
    "        a_a = reduce(lambda x, y: (x * y) % mod, operands)  # * instead of + !\n",
    "    elif algo == \"BFV\":\n",
    "        if no_add:\n",
    "            a_a = a_e\n",
    "        else:\n",
    "            a_a = bfv.sum(operands)\n",
    "    elif algo == \"BFV+batch\":\n",
    "        a_a = bfv_2.sum(operands)\n",
    "    elif algo == \"CKKS\":\n",
    "        a_a = ckks.sum_no_batch(operands)\n",
    "    elif algo == \"CKKS+batch\":\n",
    "        a_a = ckks.sum(operands)\n",
    "    \n",
    "    t_a = time.time()\n",
    "    print(f'\\t\\tAddition: {t_a - t_c} sec')\n",
    "    \n",
    "    ### perform decryption\n",
    "    if algo == \"FLASHE\":\n",
    "        a_d = flashe_decrypt(a_a)\n",
    "    elif algo == \"FLASHE+batch\":\n",
    "        a_d = flashe_decrypt(a_a)\n",
    "        a_d = _static_unbatching_padding(a_d, int_bits, element_bits, additional_bits)\n",
    "        a_d = a_d[:(int(np.prod(shape)))]\n",
    "        a_d = a_d.reshape(shape)\n",
    "    elif algo == \"Paillier\":\n",
    "        a_d = paillier_decrypt(a_a)\n",
    "    elif algo == \"Paillier+batch\":\n",
    "        a_d = paillier_decrypt(a_a)\n",
    "        a_d = _static_unbatching_padding(a_d, paillier.key_length, element_bits, additional_bits)\n",
    "        a_d = a_d[:(int(np.prod(shape)))]\n",
    "        a_d = a_d.reshape(shape)\n",
    "    elif algo == \"BFV\":\n",
    "        a_d = bfv_decrypt(a_a)\n",
    "    elif algo == \"BFV+batch\":\n",
    "        a_d = bfv_batch_decrypt(a_a)\n",
    "        a_d = np.array(a_d, dtype=np.int64)\n",
    "        a_d = a_d[:(int(np.prod(shape)))]\n",
    "        a_d = a_d.reshape(shape)\n",
    "    elif algo == \"CKKS\":\n",
    "        a_d = ckks_decrypt(a_a)\n",
    "    elif algo == \"CKKS+batch\":\n",
    "        a_d = ckks_batch_decrypt(a_a)\n",
    "    \n",
    "    t_d = time.time()\n",
    "    print(f'\\t\\tDecryption: {t_d - t_a} sec')\n",
    "    \n",
    "    ### perform unquantization\n",
    "    if algo == \"CKKS\" or \"CKKS+batch\":\n",
    "        a_u = [a_d]\n",
    "    else:\n",
    "        if algo == \"BFV\" or algo == \"BFV+batch\":\n",
    "            a_d = np.array(a_d).reshape(shape)\n",
    "        print(f'\\t\\ta_d = {a_d[0][:5]}')\n",
    "        print(f'\\t\\ta_d = {a_d[0][-5:]}')\n",
    "        a_u = unquantize(a_d, alphas, element_bits, num_clients)\n",
    "        t_u = time.time()\n",
    "#     print(f'\\t\\tUnquantization: {t_u - t_d} sec')\n",
    "\n",
    "    \n",
    "    print(f'\\t\\ta * 10 = {a_u[0][:5]}')\n",
    "    print(f'\\t\\ta * 10 = {a_u[0][-5:]}')\n",
    "    \n",
    "    return t_e - begin, t_a - t_c, t_d - t_a, l_e_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for file saving\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def rec_d():\n",
    "    return defaultdict(rec_d)\n",
    "\n",
    "result_dict = rec_d()\n",
    "\n",
    "save_path = os.path.join(os.getcwd(), 'big-table.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a_dict = {}\n",
    "a_q_dict = {}\n",
    "l_c_dict = {}\n",
    "expected_dict = {}\n",
    "for case in test_cases:\n",
    "    print(f'[CASE] {case}')\n",
    "    begin = time.time()\n",
    "\n",
    "    ### generate data\n",
    "    a = np.random.random(case)\n",
    "    print(f'\\ta = {a[:5]}')\n",
    "\n",
    "    t_g = time.time()\n",
    "    print(f'\\tGenerate data: {t_g - begin} sec')\n",
    "\n",
    "    a_q, alphas = quantize([[a]], element_bits)\n",
    "    a_q = a_q[0]\n",
    "    a_c = compress_multi(a_q[0], int_bits)\n",
    "    #     a_b = compress_pickle.dumps(a_c, 'bz2')\n",
    "    a_b = pickle.dumps(a_c)\n",
    "    l_c = len(a_b)\n",
    "    \n",
    "    l_c_dict[case] = l_c\n",
    "\n",
    "    a_b_float = pickle.dumps(a)\n",
    "    l_c_float = len(a_b_float)\n",
    "\n",
    "    expected = (np.array(a) * num_clients).tolist()\n",
    "    \n",
    "    a_q_dict[case] = a_q\n",
    "    a_dict[case] = a\n",
    "    expected_dict[case] = expected\n",
    "\n",
    "\n",
    "for algo in algos:\n",
    "    for case in test_cases:\n",
    "        print(algo, case)\n",
    "        expected = expected_dict[case]\n",
    "        print(f'\\ta * 10 = {expected[:5]}')\n",
    "        print(f'\\ta * 10 = {expected[-5:]}')\n",
    "        \n",
    "        no_add = False\n",
    "        if case > 65536:\n",
    "            if algo == \"BFV\":\n",
    "                continue\n",
    "        if case > 16384:\n",
    "            if algo == \"CKKS\":\n",
    "                continue\n",
    "            if algo == \"BFV\":\n",
    "                no_add = True\n",
    "\n",
    "        t_e, t_a, t_d, l_e_c = test_an_algo(a_dict[case], a_q_dict[case], alphas, algo, no_add)\n",
    "\n",
    "        result_dict[case][algo]['t_e'] = t_e\n",
    "        result_dict[case][algo]['t_a'] = t_a\n",
    "        result_dict[case][algo]['t_d'] = t_d\n",
    "        result_dict[case][algo]['l_c'] = l_c_dict[case]\n",
    "        result_dict[case][algo]['l_e_c'] = l_e_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayed_algos = [\"Paillier\", \"Paillier+batch\", \"BFV\", \"BFV+batch\", \"CKKS\", \"CKKS+batch\", \"FLASHE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayed_test_cases = [16384, 65536, 262144]\n",
    "# displayed_test_cases = [16384, 65536, 262144, 1048576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = {\n",
    "    'l_c' : 'Plaintext',\n",
    "    'l_e_c' : 'Ciphertext',\n",
    "    't_e' : 'Encryption',\n",
    "    't_d' : 'Decryption',\n",
    "    't_a' : 'Addition'\n",
    "}\n",
    "\n",
    "for case in displayed_test_cases:\n",
    "    print(f'[CASE] {case}')\n",
    "    t = {}\n",
    "    for c in cols.keys():\n",
    "        l = []\n",
    "        for algo in displayed_algos:\n",
    "            if case > 16384:\n",
    "                if algo == \"CKKS\":\n",
    "                    continue\n",
    "            if case > 65536:\n",
    "                if algo == \"BFV\":\n",
    "                    continue\n",
    "            \n",
    "            if 'l' in c:\n",
    "#                 print(case, algo, c)\n",
    "                kb = result_dict[case][algo][c] / 1024\n",
    "                if kb >= 1024:\n",
    "                    mb = kb / 1024\n",
    "                    if mb > 1024:\n",
    "                        gb = mb / 1024\n",
    "                        l.append('{:.2f} GB'.format(gb))\n",
    "                    else:\n",
    "                        l.append('{:.2f} MB'.format(mb))\n",
    "                else:\n",
    "                    l.append('{:.2f} KB'.format(kb))\n",
    "            else:\n",
    "                l.append('{:.2f} s'.format(result_dict[case][algo][c]))\n",
    "        t[cols[c]] = l\n",
    "\n",
    "    if case > 65536:\n",
    "        d = pd.DataFrame(data=t, index=displayed_algos[:2] + displayed_algos[3:4] + displayed_algos[5:])\n",
    "    elif case > 16384:\n",
    "        d = pd.DataFrame(data=t, index=displayed_algos[:4] + displayed_algos[5:])\n",
    "    else:\n",
    "        d = pd.DataFrame(data=t, index=displayed_algos)\n",
    "    print(d)\n",
    "    \n",
    "#     print('C/P:')\n",
    "#     if case > 65536:\n",
    "#         for algo in displayed_algos[:2] + displayed_algos[3:]:\n",
    "#             print(f'{algo} {result_dict[case][algo][\"l_e_c\"] / result_dict[case][algo][\"l_c\"]}')\n",
    "#     else:\n",
    "#         for algo in displayed_algos:\n",
    "#             print(f'{algo} {result_dict[case][algo][\"l_e_c\"] / result_dict[case][algo][\"l_c\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(result_dict, open(save_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(128 / 20)\n",
    "print((128 / 5) / 20)\n",
    "print(4096 / 20)\n",
    "print((4096 / 85) / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
